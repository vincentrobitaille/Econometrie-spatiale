---
title: "Exercices - Économétrie spatiale"
author: Vincent Robitaille
output:
  pdf_document: default
  html_notebook: default
---

```{r}
library(spdep)
library(tidyverse)
library(lmtest)
library(tseries)
library(spatialreg)
```

# Chapitre 1

```{r}
df1 <- read.csv("data/data1.csv",dec = ",")
```

### Q1

```{r}
fit1.1 <- lm(GVA ~ Labor_prod + Business_br, 
             data = df1)
fit1.1 |> summary()
```

Ce modèle est le modèle retenu. Le taux de naissance des entreprises n'est pas significatif dans le premier modèle et le $R²_a$ du second modèle est sensiblement plus élevé. Ce modèle permet d'expliquer environ 89% des variations observées dans le GVA.

```{r}
fit1.2 <- lm(GVA ~ Labor_prod, data = df1)
fit1.2 |> summary()
```

```{r}
fit1.3 <- lm(GVA ~ Business_br, data = df1)
fit1.3 |> summary()
```

```{r}
fit1.4 <- lm(Labor_prod ~ Business_br, data = df1)

df1 |>
  #select(Business_br, Labor_prod) |> 
  ggplot(aes(x = Business_br, y = Labor_prod)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)

fit1.4 |> summary()
  
```

? Patern géographique ?

```{r}
fit1.1 |> 
  ggplot(aes(x = .fitted, y = .resid, label = df1$Region)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_text(hjust=0, vjust=0)
```

Le test de Breusch-Pagan ne permet pas de rejeter l'hypothèse nulle d'homoscédasticité.

Le test de Jarque-Bera ne permet pas de rejeter l'hypothèse nulle de normalisé des résidus.

```{r}
fit1.1 |> 
  bptest()
fit1.1$residuals |> 
  jarque.bera.test()
```

## Chapitre 2

#### Question 2.2

*What is the meaning of spatially lagged variable ?* Le lag spatial est similaire au lag d'une série chronologique. Au lieu que la valeur $y_t$ soit en partie déterminée par les valeurs passées, on parle plutôt de la variable $y_i$ qui est influencée par les autres valeurs de la variable $y$. La valeur y observée pour un individu est donc influencée par la valeur y des autres individus avec lesquels il a une *connection* ou dont il est proche.

#### Question 2.3

*What is the meaning of row-standardization of weight matrix ? In which case is this operation beneficial ?* La matrice de poids dont les lignes sont standardisées est construite en divisant chaque élément de la ligne par la somme des éléments de cette ligne. Les éléments de la ligne de la nouvelle matrice sommes alors à zéro. Cette matrice est utile pour calculer les lag spatial en agissant comme une sorte de moyenne pondérée.

#### Exercice 2.1

```{r}
W21 <- matrix(0, nrow = 8, ncol = 8)
colnames(W21) <- c("RO11", "RO12", "RO21", "RO22", 
                   "RO31", "RO32", "RO41", "RO42")
row.names(W21) <- c("RO11", "RO12", "RO21", "RO22", 
                    "RO31", "RO32", "RO41", "RO42")
W21[1,] <- c(0, 1, 1, 0, 0, 0, 0, 1)
W21[2,] <- c(1, 0, 1, 1, 1, 0, 1, 1)
W21[3,] <- c(1, 1, 0, 1, 0, 0, 0, 0)
W21[4,] <- c(0, 1, 1, 0, 1, 0, 0, 0)
W21[5,] <- c(0, 1, 0, 1, 0, 1, 1, 0)
W21[6,] <- c(0, 0, 0, 0, 1, 0, 0, 0)
W21[7,] <- c(0, 1, 0, 0, 1, 0, 0, 1)
W21[8,] <- c(1, 1, 0, 0, 0, 0, 1, 0)
x <- mat2listw(W21, style = "W")


rom_regions <- c("R011", "RO12", "RO21", "RO22", 
                 "RO31", "RO32", "RO41", "RO42")
rom_regions <- 1:8
nbrom <- read.gal("data/romania.GAL", 
                  region.id = rom_regions)

wrom <- nbrom |> nb2listw(style = "B")

wrom2 <- nbrom |> nb2listw(style = "W")

m <- wrom |> listw2mat()

m |> as.numeric() |> mean()

mr <- read.csv("data/romania_inf_mor_rate.csv", 
               header = FALSE)

lagged_var <- lag.listw(wrom2, mr$V2)
```

#### Exercice 2.4

1.  Wales
2.  Scotland
3.  Northen Ireland
4.  North East of England
5.  North West of England
6.  Yorkshire & Humberside
7.  East Midlands
8.  West Midlands
9.  East Anglia (East of England)
10. Greater London
11. South East England
12. South West England

```{r}
ukgal <- read.gal("data/UK.GAL", region.id = 1:12)

ukl <- ukgal |> nb2listw(style = "B")
ukl |> listw2mat()
```

#### Exercice 2.5

```{r}
# Exo 2.5

ukdat <- read.csv("data/data1.csv", dec = ",")

laguk <- ukgal |> nb2listw(style = "W") |> lag.listw(ukdat$GVA)
names(laguk) <- c("Wales", "Scotland", "North Ireland", "North East of England",
                     "North West of England", "Yorkshire Humberside",
                     "East Midlands", "West Midlands", "East Anglia",
                     "Greater London", "South East England", "South West England")
laguk
```

#### Exercice 2.9

Le lien original ne fonctionnait pas, j'ai trouvé ces données comme alternative pour les besoins de l'exercice. <https://public.opendatasoft.com/explore/dataset/us-state-boundaries/table/?location=3,20.11268,7.82227&basemap=jawg.light&dataChart=eyJxdWVyaWVzIjpbeyJjb25maWciOnsiZGF0YXNldCI6InVzLXN0YXRlLWJvdW5kYXJpZXMiLCJvcHRpb25zIjp7fX0sImNoYXJ0cyI6W3siYWxpZ25Nb250aCI6dHJ1ZSwidHlwZSI6ImNvbHVtbiIsImZ1bmMiOiJBVkciLCJ5QXhpcyI6ImdpZCIsInNjaWVudGlmaWNEaXNwbGF5Ijp0cnVlLCJjb2xvciI6IiNGRjUxNUEifV0sInhBeGlzIjoibmFtZSIsIm1heHBvaW50cyI6NTAsInNvcnQiOiIifV0sInRpbWVzY2FsZSI6IiIsImRpc3BsYXlMZWdlbmQiOnRydWUsImFsaWduTW9udGgiOnRydWV9>

J'ai aussi enlevé les territoires et états américains hors continent car sinon la fonction n'arrive pas à les associer à d'autres états (aucun voisin).

```{r}

us <- read_sf("data/us-state-boundaries/us-state-boundaries.shp") |> 
  filter(!(name %in% c("Guam",
                       "Palau",
                       "Marshall Islands",
                       "Northern Mariana Islands",
                       "Fed States of Micronesia",
                       "Puerto Rico",
                       "Commonwealth of the Northern Mariana Islands",
                       "Hawaii",
                       "Alaska",
                       "United States Virgin Islands",
                       "American Samoa")))
# names(us)
# plot(us)
gus <- us |> 
  ggplot() +
  geom_sf() +
  ggtitle("Carte des états américains (incluant DC) du continent")

contus <- us |> poly2nb(queen = TRUE)

lus <- contus |> nb2listw()
usWmat <- contus |> nb2mat()
```

## Chapitre 3

#### Question 3.2

L'estimation par maximum de vraisemblance d'un modèle SARAR(1, 1) est intensif d'un point de vue computationnel et il n'existe présentement pas de preuve formelle que les MLE possèdent les propriétés asymptotiques habituelles d'un MLE (incluant estimateur consistant ?).

L'estimateur GS2SLS est consistent, mais pas pleinement efficient. L'alternative est le *Best Feasible GS2SLS* (BFG2SLS). Celui-ci atteint la borne inférieur pour la variance de l'estimateur dans les grand échantillons (Cramér-Rao ?). Numériquement intensif à calculer pour des grands échantillons.

#### Exercice 3.2

\begin{align*}
  y &= X\beta + u, \quad \quad u = \rho Wu+\varepsilon\\
  \varepsilon &= (I-\rho W)u\\
  (I-\rho W)y &= (I-\rho W)X\beta + \underbrace{(I-\rho W)u}_{\varepsilon}\\
  y &= \rho Wy + X\beta - \rho \beta WX + \varepsilon, \quad \gamma = -\rho\beta\\
  y &= \rho Wy + X\beta + \gamma WX + \varepsilon
\end{align*}

On peut voir que le SEM peut être réécrit sous la forme d'une SLM avec lag spatial des variables indépendantes. Puisque le lag spatial de $y$ fait parti des variables explicatives, l'estimation par OLS est problématique car les termes d'erreur sont corrélés avec celle-ci. De plus, la présence de $\gamma = -\rho\beta$ dans le modèle fait en sorte que le modèle n'est plus linéaire dans ses paramètres.

#### Exercice 3.6

```{r}
data(boston)
```

##### exemple 3.3

```{r}
fit1 <- lm(MEDV ~ CRIM + RM + INDUS + NOX + AGE + DIS + RAD + PTRATIO + 
             B + LSTAT + TAX, data = boston.c)
fit1 |> 
  summary()
# Test hétéroscédasticité
fit1 |> 
  bptest()
# Test normalité résidu
fit1$residuals |> 
  jarque.bera.test()

dist.centroid <- 3.99
```

```{r}
fit1 |> plot(which = c(1,2))
```

On peut voir qu'avec les graphiques et tests présentés que les résidus du modèle ne sont pas normalement distribués et qu'ils ne sont pas homoscédastiques.

On test ensuite la corrélation spatiale dans les résidus.

```{r}
boston.utm |> 
  ggplot(aes(x=x, y=y)) +
  geom_point() + 
  ggtitle("Représentation spatiale des centroïds des secteurs de recensement")
```

Comme dans l'exemple du livre, le test avec le seuil de distance à 3.99 montre la présence d'une corrélation spatiale significative dans les résidus.

```{r}
dmat1 <- dnearneigh(boston.utm, 0, d2 = dist.centroid, longlat = FALSE)
dmat1 <- dmat1 |> nb2listw()

lm.morantest(fit1, dmat1, alternative = "two.sided")
```

##### Comparaison 3.3

On peut voir que les résultats ressemblent à l'estimation de l'exemple 3.3. Les signes des coefficients sont les mêmes (à l'exception de AGE) et leurs amplitudes sont relativement semblables. Nous devons également rejeter les hypothèses de normalité et d'homoscédasticité. Nous obtenons un AIC sensiblement plus faible que celui du SLM (3021.4 vs 3034.7)

```{r}
# MLE
fit3.1 <- errorsarlm(
  formula = MEDV ~ CRIM + RM + INDUS + NOX + AGE + DIS + RAD + PTRATIO + 
             B + LSTAT + TAX, 
  data = boston.c, listw = dmat1
  )
fit3.1 |> summary()
fit3.1 |> bptest.Sarlm()
fit3.1$residuals |> jarque.bera.test()
```

L'estimation par *Feasible GLS* donne sensiblement les mêmes résultats que l'estimation par maximum de vraisemblance pour le modèle SEM. Encore une fois, les résultats sont similaires à ceux du SLM de l'exemple 3.3, mais on observe quand même des différences. On rejete toujours l'hypothèse de normalité des résidus.

```{r}
# FGLS
fit3.2 <- GMerrorsar(
  formula = MEDV ~ CRIM + RM + INDUS + NOX + AGE + DIS + RAD + PTRATIO + 
             B + LSTAT + TAX, 
  data = boston.c, listw = dmat1
  )
fit3.2 |> summary()

fit3.2$residuals |> jarque.bera.test()

```

##### Comparaison 3.4

On remarque qu'à l'exception de l'intercept, les valeurs des coefficents (sans lag) sont similaires entre l'estimation SEM et SDM de l'exemple 3.4. Puisqu'un SEM revient à un SDM lorsque $\gamma = -\rho\beta$, la différence dans l'estimation doit essentiellement provenir du fait que dans ces deux modèles, la contrainte n'est pas parfaitement respectée. Il y a également des différences remarquables dans les p-value calculées. L'AIC est sensiblement plus élevé et on rejette l'hypothèse de normalité.

```{r}
fit3.3 <- errorsarlm(
  formula = MEDV ~ CRIM + RM + INDUS + NOX, 
  data = boston.c, listw = dmat1
  )
fit3.3 |> summary()
fit3.3$residuals |> jarque.bera.test()
```

Les coefficients estimés sont très similaires à ceux du MLE. On remarque cependant que les écart-types sont plus faibles. On rejette encore l'hypothèse de normalité des résidus.

```{r}
# FGLS
fit3.4 <- GMerrorsar(
  formula = MEDV ~ CRIM + RM + INDUS + NOX, 
  data = boston.c, listw = dmat1
  )
fit3.4 |> summary()
fit3.4$residuals |> jarque.bera.test()
```

#### Exercice 3.7

Je n'arrive pas à trouver les données pour la courbe de Philips (données pas présentes à l'exemple 2.4), je fais l'exercice pour la loi d'Okun

```{r}
ita_regions <- c(2, 3, 9, 1, 15, 19, 18, 11, 17, 4, 5, 12, 6, 10, 13, 7, 14, 8, 20, 16)
nbitaly <- read.gal("data/Italy.GAL", 
                    region.id = ita_regions
                    )
witaly <- nb2listw(nbitaly)
italy_econ <- openxlsx::read.xlsx("data/ita_econ.xlsx")
colnames(italy_econ) <- c(
  # "id", 
  "Region", "Var_unempl", "Var_rGDP")

fit3.7.1 <- lm(Var_unempl ~ Var_rGDP, data = italy_econ)
fit3.7.1 |> summary()
fit3.7.1 |> bptest()
fit3.7.1$residuals |> jarque.bera.test()
```

Résultats différents de l'exemple 2.3 ?

```{r}
lm.morantest(fit3.7.1, listw = witaly, alternative = "two.sided")

# Fit SDM
fit3.7.2 <- lagsarlm(
  formula = Var_unempl ~ Var_rGDP,
  data = italy_econ,
  listw = witaly,
  type = "mixed"
)

fit3.7.2 |> summary()
```

## Chapitre 4

#### Question 4.1

Lorsque les individus d'un jeu de données sont des régions, leurs différences significatives en terme de taille et de forme peuvent influencer la taille des chocs associés. La variance pourrait ainsi être plus élevée dans les régions plus grandes ou importantes et nous aurions alors de l'hétéroscédasticité.

#### Question 4.5

Une estimation classique par maximum de vraisemblance se base sur l'hypothèse que les termes d'erreur sont iid.

De plus, la vraisemblance *initiale* utilise la variable latente $y^\bullet$, mais puisque celle-ci n'est pas connue, la forme réduite doit être utilisée. Celle-ci comporte sont lot de complications au niveau de l'estimation numérique. La méthode trouvée pour y arriver (EM) cause cependant un biais dans les estimations. Des erreurs importantes dans le calcul du determinant de la matrice $\Omega$ peut survenir dans certains cas étant donné l'utilisation de méthodes d'approximation face à la complexitié computationnelle.

#### Question 4.7

À FAIRE

#### Question 4.14

L'utilisation d'une approche bayésienne permet d'incorporer de l'information a priori concernant les paramètres du modèle à estimer. Les estimations bayésiennes peuvent mener à des écart-types plus élevés, mais ceux-ci proviennent généralement par l'incertitude ou l'information fournie à travers le prior.

De plus, le cadre bayésien traite les paramètres comme des variables aléatoires, ce qui nous permet d'estimer la probabilité qu'un paramètre se trouve dans un intervalle de confiance. Cette interprétation est souvent plus intuitive que l'approche par intervalle de confiance et p-values.

#### Exercice 4.1

Soit le niveau 1:

$$y=X\beta+\varepsilon \quad \quad \varepsilon|X \stackrel{iid}{\sim}N\left(0, \sigma²_\varepsilon I_n\right)$$

Soit le niveau 2 composé de $m$ niveaux, contenant chacun $n_m$ régions de niveau 1:

$\overline{y}$ un agrégat de $y$ selon la matrice d'agrégation $G_{m\times n}$ t.q. $\overline{y} = Gy$

$$\overline{y} = GX\beta + G\varepsilon$$

Posons les éléments de $G$ comme $g_{ji}$ égal à 1 si l'individu i fait parti du groupe j et zéro sinon. Ainsi, si nous avons $g_{11}=1$, ça implique que $g_{j1} = 0$ pour tout j dans m, sauf le premier groupe. On se retrouve donc avec une matrice diagonale dans l'expression de la variance de résidus.

Posons $G'G = G^*$, un matrice diagonale.

L'expression de la variance pour le modèle de niveau 2 devient donc:

$$\overline{\varepsilon}|\overline{X} \stackrel{iid}{\sim} N\left(0, \sigma²_\varepsilon G^*\right)$$

On peut rapidement voir que la variance des résidus dépend du groupe dans lequel il se trouve puisque:

$$\overline{\varepsilon}_m|\overline{X} \stackrel{iid}{\sim} N\left(0, \sigma²_\varepsilon G^*_m\right)$$

#### Exercice 4.3

```{r}
library(sphet)
eu <- readxl::read_xlsx("data/econ_UE.xlsx")
ue_pays <- eu$Country_code
df_4_3 <- read.gal("data/eu.GAL", region.id = ue_pays)
euw <- df_4_3 |> nb2listw(style = "W")

fit_eu1 <- gstslshet(Growth_2010_2011 ~ pct_exp_educ_2009, data = eu, listw = euw)
fit_eu1 |> 
  summary()
```


#### Exercice 4.4

$$y^\bullet = X\beta + u \quad \quad y = I(y^\bullet > 0)$$
$$u = \rho Wu+ \varepsilon \quad \quad \varepsilon|X \stackrel{iid}{\sim}N(0,I)$$
$$Pr\left(Y=1|X\right) = Pr\left(Y^\bullet>0\right) = Pr\left(X\beta+u>0\right)$$
$$=Pr\left(X\beta+(I-\rho W)^{-1}\varepsilon > 0\right) = Pr\left((I-\rho W)^{-1}\varepsilon < X\beta\right) = Pr\left(\varepsilon<(I-\rho W)X\beta\right)$$
$$\Longrightarrow Pr\left[y_i = 1|x_i\right] = \Phi\left[(I-\rho W) X\beta\right] \quad \& \quad Pr\left[y_i = 0|x_i\right] = 1- \Phi\left[(I-\rho W) X\beta\right]$$

$$\mathcal{L}\left(\beta,\rho; Y, X\right) = \prod_{i=1}^n \left[\Phi\left((I-\rho W_i)x'_i\beta\right)\right]^{y_i} \left[1- \Phi\left((I-\rho W_i)x'_i\beta\right)\right]^{(1-y_i)}$$
$$l\left(\beta, \rho; Y,X\right) = \sum^n_{i=1} \Biggl( y_i \log\biggr[\Phi \left(\left(I-\rho W_i\right)x'_i\beta\right)\biggr]  + (1-y_i) \log\biggr[1 - \Phi \left(\left(I-\rho W_i\right)x'_i\beta\right)\biggr]\Biggl)$$
$$\frac{\partial l}{\partial \rho} = \sum_{i=1}^n \left[y_i\frac{\phi\left((I-\rho W_i\right)x_i'\beta) \left(-W_i x'_i\beta\right)}{\Phi \left(\left(I-\rho W_i\right)x'_i\beta\right)} + (1-y_i) \frac{\Bigl[-\phi\left((I-\rho W_i\right)x_i'\beta)\Bigl] \left(-W_i x'_i\beta\right)}{\Bigl[1-\Phi \left(\left(I-\rho W_i\right)x'_i\beta\right)\Bigl]}\right]$$
$$\frac{\partial l}{\partial \beta} = \sum_{i=1}^n \left[y_i\frac{\phi\left((I-\rho W_i\right)x_i'\beta) \left((I-\rho W_i)x_i'\right)}{\Phi \left(\left(I-\rho W_i\right)x'_i\beta\right)} + (1-y_i) \frac{\Bigl[-\phi\left((I-\rho W_i\right)x_i'\beta)\Bigl] \left((I-\rho W_i)x_i'\right)}{\Bigl[1-\Phi \left(\left(I-\rho W_i\right)x'_i\beta\right)\Bigl]}\right]$$

#### Exercice 4.5


```{r}
library(spldv)
eu

fit0_45 <- glm(hitec_intensity ~ pct_exp_educ_2009 + Growth_2010_2011, 
    data = eu,
    family = binomial(link = "probit"))
fit0_45 |> 
  summary()

fit1_45 <- sbinaryGMM(hitec_intensity ~ pct_exp_educ_2009 + Growth_2010_2011, 
    data = eu,
    listw = euw,
    link = "probit")
fit1_45 |> 
  summary()
fit1_45 |> 
  impacts()

fit2_45 <- sbinaryLGMM(hitec_intensity ~ pct_exp_educ_2009 + Growth_2010_2011, 
    data = eu,
    listw = euw,
    link = "probit")
fit2_45 |> 
  summary()
fit2_45 |> 
  impacts()

```


#### Exercice 4.9 (sans l'estimation)

$$p(\beta, \sigma^2, \lambda | y) \propto p(\lambda) (\sigma^2) p(\beta|\sigma^2) p(y|\beta, \sigma^2, \lambda)$$

Nous pouvons définir les priors $p(\beta|sigma^2)$ et $p(\sigma^2)$ comme étant NIG, soient:

$$(\beta|\sigma^2) \sim N(\mu_{\beta}, \sigma^2V), \quad \text{V une matrice diagonale positive}$$

$$(\sigma^2) \sim IG(a_1,b_1)$$

Nous avons fait l'hypothèse que le paramètre $p(\lambda)$ est indépendant de $p(\beta, \sigma^2)$. On pourrait définir le prior comme étant $U(-1,1)$, mais le livre mentionne qu'il est préférable de choisir une densité beta de la transformation de $\lambda$.  Cela permet aussi de plus facilement adapter la forme du prior de $\lambda$ qu'en restant avec une loi uniforme.

Ainsi,

$$\lambda^* = \frac{\lambda + 1}{2}, \quad \lambda^* \sim \text{Beta}(a_2,b_2)$$

La loi a posteriori n'est malheureusement pas conjuguée et n'est pas une expression connue. On peut ensuite réaliser l'estimation à l'aide de la loi a posteriori par l'algorithme de Metropolis-Hastings.
